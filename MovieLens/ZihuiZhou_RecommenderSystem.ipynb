{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split,KFold\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "      <td>978300760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>661</td>\n",
       "      <td>3</td>\n",
       "      <td>978302109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>914</td>\n",
       "      <td>3</td>\n",
       "      <td>978301968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3408</td>\n",
       "      <td>4</td>\n",
       "      <td>978300275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2355</td>\n",
       "      <td>5</td>\n",
       "      <td>978824291</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  movie_id  rating  timestamp\n",
       "0        1      1193       5  978300760\n",
       "1        1       661       3  978302109\n",
       "2        1       914       3  978301968\n",
       "3        1      3408       4  978300275\n",
       "4        1      2355       5  978824291"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the ratings.csv file into the dataframe\n",
    "df = pd.read_csv('ml-1m/ratings.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since the user_id and movie_id might not be consecutive, we map them into the range\n",
    "LE = LabelEncoder()\n",
    "users = LE.fit_transform(df['user_id'].values)\n",
    "movies = LE.fit_transform(df['movie_id'].values)\n",
    "ratings = df['rating'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into 60% as training, 20% as validation, 20% as test\n",
    "user, user_test, movie, movie_test, rating, rating_test = train_test_split(users, movies, ratings, test_size=0.2)\n",
    "user_train, user_val, movie_train, movie_val, rating_train, rating_val = train_test_split(user,movie,rating,test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 6040 unique users in the dataset\n",
      "There are 3706 unique movies in the dataset\n"
     ]
    }
   ],
   "source": [
    "# Data analysis\n",
    "print('There are',users.max()+1,'unique users in the dataset')\n",
    "print('There are',movies.max()+1,'unique movies in the dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Prediction ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrix factorization using: https://datajobs.com/data-science-repo/ Recommender-Systems-[Netflix].pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter initialization\n",
    "rating_mean = np.mean(rating_train)\n",
    "\n",
    "def initialization(F,U,I):\n",
    "    bu_0 = np.random.normal(0,0.0001,U)\n",
    "    bi_0 = np.random.normal(0,0.0001,I)\n",
    "    pu = np.random.normal(0,1/max(1,np.sqrt(F)),(U,F))\n",
    "    qi = np.random.normal(0,1/max(1,np.sqrt(F)),(I,F))\n",
    "    return bu_0,bi_0,pu,qi\n",
    "\n",
    "bu_0,bi_0,pu,qi=initialization(2,users.max()+1,movies.max()+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6040,), (3706,), (6040, 2), (3706, 2))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bu_0.shape,bi_0.shape,pu.shape,qi.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrix decomposition\n",
    "def model_prediction(U,I,rating_mean,bu_0,bi_0,pu,qi):\n",
    "    bu = bu_0[U]\n",
    "    bi = bi_0[I]\n",
    "    pu = pu[U]\n",
    "    qi = qi[I]\n",
    "    r = rating_mean + bu + bi + np.sum(pu*qi,axis=1)\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.4132626 , 3.8881893 , 3.86157201, 3.93129115, 3.42878726,\n",
       "       3.34759146, 4.00533156, 3.76057187, 4.16789689, 3.40888691])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating = model_prediction(user_train,movie_train,rating_mean,bu_0,bi_0,pu,qi)\n",
    "rating[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0004374309093889802"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(rating_train - rating)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Function ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As we assume no regularization penalty for the biases\n",
    "\n",
    "def loss(rating,U,I,rating_mean,bu_0,bi_0,pu,qi):\n",
    "    L = np.mean((rating-model_prediction(U,I,rating_mean,bu_0,bi_0,pu,qi))**2) # 1/N * sum == mean, do not need to np.sum first\n",
    "    return L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.807685777390463"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss(rating_train,user_train,movie_train,rating_mean,bu_0,bi_0,pu,qi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6040"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bu_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Algorithm ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learning(rating,U,I,rating_mean,bu_0,bi_0,pu,qi,B,lr,p):\n",
    "    permutation = np.random.permutation(len(rating))\n",
    "    for i in range(0,len(rating),B):\n",
    "        ind = permutation[i:i+B]\n",
    "        user = U[ind]\n",
    "        item = I[ind]\n",
    "        rate = rating[ind]\n",
    "        bu = bu_0[user]\n",
    "        bi = bi_0[item]\n",
    "        pun = pu[user]\n",
    "        qin = qi[item]\n",
    "        dr = rate-(rating_mean+bu+bi+np.sum(pun*qin,axis=1))\n",
    "        bu_0[user] += lr*dr\n",
    "        bi_0[item] += lr*dr\n",
    "        pu[user] += lr*(dr[:,np.newaxis]*qin-p*pun) # pu remains initialized, but not substituted\n",
    "        qi[item] += lr*(dr[:,np.newaxis]*pun-p*qin)\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitdata(user_train,movie_train,rating_train,user_val,movie_val,rating_val,F,lr,step,B,p):\n",
    "    train_mean = np.mean(rating_train)\n",
    "    bu_0,bi_0,pu,qi = initialization(F,users.max()+1,movies.max()+1)\n",
    "    for k in range(step):  \n",
    "        train_loss = loss(rating_train,user_train,movie_train,train_mean,bu_0,bi_0,pu,qi)    \n",
    "        learning(rating_train,user_train,movie_train,train_mean,bu_0,bi_0,pu,qi,B,lr,p)\n",
    "        if (k % (step//10))==0:\n",
    "            val_loss = loss(rating_val,user_val,movie_val,train_mean,bu_0,bi_0,pu,qi)\n",
    "            print(\"\\t\",k,train_loss,val_loss)\n",
    "    train_loss = loss(rating_train,user_train,movie_train,train_mean,bu_0,bi_0,pu,qi)\n",
    "    val_loss = loss(rating_val,user_val,movie_val,train_mean,bu_0,bi_0,pu,qi)\n",
    "    print(\"\\tFinal\",train_loss,val_loss)\n",
    "    return val_loss,train_mean,bu_0,bi_0,pu,qi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecommenderModel:\n",
    "    def __init__(self,F,lr,step,B,p):\n",
    "        self.F = F\n",
    "        self.lr = lr\n",
    "        self.step = step\n",
    "        self.B = B\n",
    "        self.p = p\n",
    "    def fit(self,user_train,movie_train,rating_train,user_val,movie_val,rating_val):\n",
    "        loss,train_mean,bu_0,bi_0,pu,qi = fitdata(user_train,movie_train,rating_train,user_val,movie_val,rating_val,self.F,self.lr,self.step,self.B,self.p)\n",
    "        self.loss = loss\n",
    "        self.train_mean = train_mean\n",
    "        self.bu_0 = bu_0\n",
    "        self.bi_0 = bi_0\n",
    "        self.pu = pu\n",
    "        self.qi = qi\n",
    "        return loss\n",
    "    def predict(self,U,I):\n",
    "        prediction = model_prediction(U,I,self.rating_mean,self.bu_0,self.bi_0,self.pu,self.qi)\n",
    "        return prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Popularity model with F = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t 0 1.2490321035581162 0.8607817836824053\n",
      "\t 1 0.8392866674189221 0.8603226064327695\n",
      "\t 2 0.8348219343375991 0.8580382620467261\n",
      "\t 3 0.8322262735560804 0.8601634941990214\n",
      "\t 4 0.8338020064033137 0.8601042840861302\n",
      "\t 5 0.8338655313544115 0.8599042574348835\n",
      "\t 6 0.8339136386414858 0.8577751990471153\n",
      "\t 7 0.8329964408320699 0.8608780821566315\n",
      "\t 8 0.8348503146502935 0.8624116353444549\n",
      "\t 9 0.8353883809260839 0.8615478484029556\n",
      "\t 10 0.8349077046920185 0.8596321098170543\n",
      "\tFinal 0.834702058761575 0.8596321098170543\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8596321098170543"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=RecommenderModel(F=0,lr=0.05,step=11,B=50,p=0.1)\n",
    "model.fit(user_train,movie_train,rating_train,user_val,movie_val,rating_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t 0 2.2806303748097103 0.8682245022628453\n",
      "\t 1 0.8382091190176469 0.8629120557632577\n",
      "\t 2 0.8337981385846155 0.8596770691591971\n",
      "\t 3 0.8296972503478163 0.8580264653698083\n",
      "\t 4 0.8277831429228325 0.8523534319604142\n",
      "\t 5 0.8203012498284284 0.8451047115741568\n",
      "\t 6 0.809131521888325 0.836454437704149\n",
      "\t 7 0.800790018973115 0.8336673904384306\n",
      "\t 8 0.7948273065419914 0.8312759320293241\n",
      "\t 9 0.7933532185442821 0.8309902471757691\n",
      "\t 10 0.7920080607268396 0.8280964321890085\n",
      "\tFinal 0.7878154272870911 0.8280964321890085\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8280964321890085"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=RecommenderModel(F=1,lr=0.05,step=11,B=50,p=0.1)\n",
    "model.fit(user_train,movie_train,rating_train,user_val,movie_val,rating_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t 0 2.214974372223453 0.8661004909775942\n",
      "\t 1 0.8382758991401661 0.8608651269761817\n",
      "\t 2 0.8310138337854867 0.8616741767254371\n",
      "\t 3 0.8307345391503373 0.8583440543139387\n",
      "\t 4 0.8279023754515824 0.8515615933981234\n",
      "\t 5 0.8205000739213909 0.8454894498455862\n",
      "\t 6 0.8112707274929216 0.8359525510921476\n",
      "\t 7 0.7997378604936579 0.8315504996092236\n",
      "\t 8 0.795446336251474 0.8319011582058352\n",
      "\t 9 0.7922045099843366 0.8271199301012201\n",
      "\t 10 0.789044409467505 0.8284732544930842\n",
      "\tFinal 0.7882533930733214 0.8284732544930842\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8284732544930842"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=RecommenderModel(F=1,lr=0.05,step=11,B=30,p=0.1)\n",
    "model.fit(user_train,movie_train,rating_train,user_val,movie_val,rating_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning the hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F 0 Batch size: 30\n",
      "\t 0 1.2490273530956846 0.8600234527227132\n",
      "\t 1 0.838244918541423 0.8583033343705522\n",
      "\t 2 0.8345088932273065 0.8596400223345517\n",
      "\t 3 0.8343270974078659 0.8594536449167575\n",
      "\t 4 0.8329373090540827 0.8604339439861656\n",
      "\t 5 0.8349310899453808 0.8598597410280928\n",
      "\t 6 0.8339769733870228 0.8608774901407457\n",
      "\t 7 0.8344690220770251 0.8578694262900437\n",
      "\t 8 0.8320483805182399 0.86044354045571\n",
      "\t 9 0.8344442373516417 0.8631675506832558\n",
      "\t 10 0.8358015557829376 0.8582362797082744\n",
      "\tFinal 0.8325333314296496 0.8582362797082744\n",
      "Best F is: 0 Best Batch size is: 30 corresponding loss is: 0.8582362797082744\n",
      "F 0 Batch size: 50\n",
      "\t 0 1.249032955531158 0.8635112505795619\n",
      "\t 1 0.8411186135055914 0.8584509299884575\n",
      "\t 2 0.8352230187773237 0.8616182180214179\n",
      "\t 3 0.8351805823676766 0.8617883987648254\n",
      "\t 4 0.8363214962774471 0.8591501802430792\n",
      "\t 5 0.8343560018467354 0.8593546046669627\n",
      "\t 6 0.8343757836931746 0.859656730562744\n",
      "\t 7 0.8329362151653988 0.8606856310471586\n",
      "\t 8 0.8349376729518714 0.8623093230796273\n",
      "\t 9 0.8359101484716072 0.8607996903427175\n",
      "\t 10 0.8338119031918302 0.8597708060529344\n",
      "\tFinal 0.8333477943066799 0.8597708060529344\n",
      "Best F is: 0 Best Batch size is: 50 corresponding loss is: 0.8597708060529344\n",
      "F 0 Batch size: 60\n",
      "\t 0 1.2490298836893012 0.8611398147530307\n",
      "\t 1 0.8387587694799993 0.8599837299066854\n",
      "\t 2 0.8358327387945397 0.8596241325864735\n",
      "\t 3 0.8344881752626842 0.8596074238311723\n",
      "\t 4 0.8327629649001838 0.859738223981356\n",
      "\t 5 0.8348461164182924 0.8601667229838387\n",
      "\t 6 0.8339786485931121 0.8587265124712504\n",
      "\t 7 0.8326623821670227 0.8576221930814867\n",
      "\t 8 0.8333066613574434 0.8583439867617415\n",
      "\t 9 0.8317236252286768 0.8585887251793021\n",
      "\t 10 0.8339000526097438 0.8610558891361811\n",
      "\tFinal 0.8346957443677224 0.8610558891361811\n",
      "Best F is: 0 Best Batch size is: 60 corresponding loss is: 0.8610558891361811\n",
      "F 1 Batch size: 30\n",
      "\t 0 2.163428907071426 0.8647432556256561\n",
      "\t 1 0.8376353187330422 0.8611709720730705\n",
      "\t 2 0.831478578603677 0.8619565225977708\n",
      "\t 3 0.8298388457525447 0.8597589144143685\n",
      "\t 4 0.830644161710507 0.8568057128944062\n",
      "\t 5 0.8251853137361085 0.8514009771702908\n",
      "\t 6 0.8192719853398543 0.8421830254498058\n",
      "\t 7 0.8073310813243404 0.8355615576668258\n",
      "\t 8 0.8000538709530511 0.8309521015216864\n",
      "\t 9 0.7940311732758172 0.8292966124975721\n",
      "\t 10 0.7917226906120739 0.8282754175932512\n",
      "\tFinal 0.7906958619817526 0.8282754175932512\n",
      "Best F is: 1 Best Batch size is: 30 corresponding loss is: 0.8282754175932512\n",
      "F 1 Batch size: 50\n",
      "\t 0 2.344906706932681 0.8666160481875865\n",
      "\t 1 0.8390797013001584 0.8609389632479154\n",
      "\t 2 0.8316819515024818 0.8643118509639893\n",
      "\t 3 0.8340603603794216 0.8591833689604191\n",
      "\t 4 0.8294152912102438 0.8583267415626353\n",
      "\t 5 0.8267499033881762 0.8487259152267723\n",
      "\t 6 0.8166347758315078 0.8400309571701665\n",
      "\t 7 0.8046337461858025 0.8350846855150548\n",
      "\t 8 0.7977572666909097 0.8320186341868323\n",
      "\t 9 0.79317663912746 0.8286085840203254\n",
      "\t 10 0.7905646596265585 0.8303653786926064\n",
      "\tFinal 0.7911509415033617 0.8303653786926064\n",
      "Best F is: 1 Best Batch size is: 50 corresponding loss is: 0.8303653786926064\n",
      "F 1 Batch size: 60\n",
      "\t 0 2.162066200009274 0.867017811391642\n",
      "\t 1 0.8397920907221019 0.8607371083923231\n",
      "\t 2 0.831895568721415 0.8572874980259323\n",
      "\t 3 0.8288072678661821 0.8574940006426942\n",
      "\t 4 0.8269955771905726 0.8497348066126083\n",
      "\t 5 0.8174084158078113 0.8391184751030607\n",
      "\t 6 0.8060608346693228 0.8358626031603397\n",
      "\t 7 0.7995571983579389 0.8322023827313597\n",
      "\t 8 0.7944931764343683 0.8291006293126257\n",
      "\t 9 0.7918756593317103 0.8276953418077387\n",
      "\t 10 0.7904674851653584 0.8276027591395726\n",
      "\tFinal 0.7881588382276218 0.8276027591395726\n",
      "Best F is: 1 Best Batch size is: 60 corresponding loss is: 0.8276027591395726\n",
      "F 5 Batch size: 30\n",
      "\t 0 1.4422874801283347 0.8642258320540908\n",
      "\t 1 0.8296281228792776 0.8561533028523824\n",
      "\t 2 0.8196406975881555 0.8449517047655768\n",
      "\t 3 0.8052830439948871 0.8318313337401572\n",
      "\t 4 0.7891441052472881 0.8264188824105209\n",
      "\t 5 0.7791668960617882 0.8224322149808009\n",
      "\t 6 0.77176311419883 0.8183097932114632\n",
      "\t 7 0.7649393200976905 0.8137343726123204\n",
      "\t 8 0.758382639544868 0.813173737641165\n",
      "\t 9 0.7527890330231043 0.8097696673202358\n",
      "\t 10 0.7474219916680528 0.8086556020508947\n",
      "\tFinal 0.742752083583934 0.8086556020508947\n",
      "Best F is: 5 Best Batch size is: 30 corresponding loss is: 0.8086556020508947\n",
      "F 5 Batch size: 50\n",
      "\t 0 1.4472589326865148 0.8613752334018571\n",
      "\t 1 0.8289336567409346 0.857788539749543\n",
      "\t 2 0.8218845800378191 0.851329437303667\n",
      "\t 3 0.8118036018815545 0.8372674578146445\n",
      "\t 4 0.7941667330798315 0.8296693389545409\n",
      "\t 5 0.7831163455119416 0.8225460443512073\n",
      "\t 6 0.7727549610034626 0.8194376245345328\n",
      "\t 7 0.7648655981980641 0.8179277966101217\n",
      "\t 8 0.7599926241056054 0.8145270823634031\n",
      "\t 9 0.755896847710026 0.8108779362064904\n",
      "\t 10 0.7503957888262142 0.807743492762835\n",
      "\tFinal 0.745110302050621 0.807743492762835\n",
      "Best F is: 5 Best Batch size is: 50 corresponding loss is: 0.807743492762835\n",
      "F 5 Batch size: 60\n",
      "\t 0 1.4444065597646218 0.8643343154087912\n",
      "\t 1 0.8305117912867057 0.857122763378152\n",
      "\t 2 0.8207202958456672 0.8489524057321861\n",
      "\t 3 0.8090682200630804 0.837262926748992\n",
      "\t 4 0.7931358946734509 0.8329921625455263\n",
      "\t 5 0.7862310123934891 0.8288255818544731\n",
      "\t 6 0.778994920797732 0.8229380284916181\n",
      "\t 7 0.7685217793199589 0.8183589575200957\n",
      "\t 8 0.763958469721037 0.8164022589636148\n",
      "\t 9 0.7575085286190842 0.8103468432323901\n",
      "\t 10 0.7493625334329944 0.8109141604472548\n",
      "\tFinal 0.7480954040925519 0.8109141604472548\n",
      "Best F is: 5 Best Batch size is: 60 corresponding loss is: 0.8109141604472548\n",
      "F 10 Batch size: 30\n",
      "\t 0 1.3479753994435928 0.8650997285185601\n",
      "\t 1 0.8263108716446732 0.854373219445484\n",
      "\t 2 0.8149655361488413 0.8409733652607465\n",
      "\t 3 0.796502505577913 0.830736737402439\n",
      "\t 4 0.7805920364179283 0.8259802944683773\n",
      "\t 5 0.7688110868707447 0.8189433784875019\n",
      "\t 6 0.7576821094285625 0.8129694739985062\n",
      "\t 7 0.7474451543535585 0.8086511167587035\n",
      "\t 8 0.7381792022124356 0.8061303962564687\n",
      "\t 9 0.7324239277875861 0.8012071859171292\n",
      "\t 10 0.7251366428220525 0.8000376793106008\n",
      "\tFinal 0.7209479405666923 0.8000376793106008\n",
      "Best F is: 10 Best Batch size is: 30 corresponding loss is: 0.8000376793106008\n",
      "F 10 Batch size: 50\n",
      "\t 0 1.3468745815311913 0.8615775163210373\n",
      "\t 1 0.824537543535159 0.8606712638992602\n",
      "\t 2 0.8189902596721345 0.84825421363129\n",
      "\t 3 0.8033454814544236 0.831365534205462\n",
      "\t 4 0.7814871145163234 0.8255990436952372\n",
      "\t 5 0.7698480127548138 0.8183004096236836\n",
      "\t 6 0.7584035850182892 0.8126475132432556\n",
      "\t 7 0.7481951024968416 0.8089901391144962\n",
      "\t 8 0.7405068534872613 0.805994765076846\n",
      "\t 9 0.7326830483303627 0.8020536453744379\n",
      "\t 10 0.7267603499159019 0.804152722585577\n",
      "\tFinal 0.7239544261050412 0.804152722585577\n",
      "Best F is: 10 Best Batch size is: 50 corresponding loss is: 0.804152722585577\n",
      "F 10 Batch size: 60\n",
      "\t 0 1.3470986290215043 0.8623170848400201\n",
      "\t 1 0.8243770354935074 0.855593155236215\n",
      "\t 2 0.8147540238284101 0.8423461025602741\n",
      "\t 3 0.7998168681402629 0.8305233382665305\n",
      "\t 4 0.7812546135955234 0.8229535806082346\n",
      "\t 5 0.7686695018705515 0.8181026384751314\n",
      "\t 6 0.756563243786206 0.8125141413013162\n",
      "\t 7 0.7480114236660234 0.8085226652040396\n",
      "\t 8 0.7383600192444001 0.8029135340598376\n",
      "\t 9 0.7299973420946616 0.8037169185333624\n",
      "\t 10 0.7254561162737811 0.7993656189005807\n",
      "\tFinal 0.7195448008839059 0.7993656189005807\n",
      "Best F is: 10 Best Batch size is: 60 corresponding loss is: 0.7993656189005807\n"
     ]
    }
   ],
   "source": [
    "Fs = [0,1,5,10]\n",
    "Bs = [30,50,60]\n",
    "final = []\n",
    "best_loss = 10\n",
    "best_F = 0\n",
    "best_B = 0\n",
    "for F in Fs:\n",
    "    for B in Bs:\n",
    "        print('F',F, 'Batch size:',B)\n",
    "        model = RecommenderModel(F=F,lr=0.05,step=11,B=B,p=0.1)\n",
    "        loss1 = model.fit(user_train,movie_train,rating_train,user_val,movie_val,rating_val) # Need to keep the variable different from the global variable function\n",
    "        final.append((F,B,loss1))\n",
    "        if loss1 < best_loss:\n",
    "            best_loss = loss1\n",
    "            best_F = F\n",
    "            best_Batch = B\n",
    "        print('Best F is:', F,'Best Batch size is:', B, 'corresponding loss is:',loss1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">corresponding loss value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Batch size</th>\n",
       "      <th>30</th>\n",
       "      <th>50</th>\n",
       "      <th>60</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.858236</td>\n",
       "      <td>0.859771</td>\n",
       "      <td>0.861056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.828275</td>\n",
       "      <td>0.830365</td>\n",
       "      <td>0.827603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.808656</td>\n",
       "      <td>0.807743</td>\n",
       "      <td>0.810914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.800038</td>\n",
       "      <td>0.804153</td>\n",
       "      <td>0.799366</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           corresponding loss value                    \n",
       "Batch size                       30        50        60\n",
       "F                                                      \n",
       "0                          0.858236  0.859771  0.861056\n",
       "1                          0.828275  0.830365  0.827603\n",
       "5                          0.808656  0.807743  0.810914\n",
       "10                         0.800038  0.804153  0.799366"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df = pd.DataFrame(final,columns=['F','Batch size','corresponding loss value'])\n",
    "final_pivot = final_df.pivot(index='F', columns='Batch size')\n",
    "final_pivot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading from the above dataframe, we could notice that minimum loss value is achieved at F=10 and Batch size=60. Then, to find the best F, I use 5-fold cross validation to test on F=[9,10,11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = KFold(5,shuffle=True)\n",
    "folds = []\n",
    "for fold in kfold.split(users):\n",
    "    folds.append(fold)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(model,users,movies,ratings,folds):\n",
    "    loss_sum = []\n",
    "    count = 0\n",
    "    for train,val in folds:\n",
    "        users_train = users[train]\n",
    "        movies_train = movies[train]\n",
    "        ratings_train = ratings[train]\n",
    "        users_val = users[val]\n",
    "        movies_val = movies[val]\n",
    "        ratings_val = ratings[val]\n",
    "        loss2 = model.fit(users_train,movies_train,ratings_train,\n",
    "                                   users_val,movies_val,ratings_val)      \n",
    "        loss_sum.append(loss2)\n",
    "        print('---------Fold:', count+1, 'loss:',loss2,'----------')\n",
    "        count += 1\n",
    "    loss_sum = np.array(loss_sum)\n",
    "    return loss_sum.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F 9\n",
      "\t 0 1.3601829650084232 0.8656719885684826\n",
      "\t 1 0.8325665828495444 0.8585337065705028\n",
      "\t 2 0.82411262930501 0.838898887287395\n",
      "\t 3 0.8028517352963126 0.8283550602000007\n",
      "\t 4 0.7881228551437421 0.8167946777419491\n",
      "\t 5 0.7721780097412038 0.8094158340990715\n",
      "\t 6 0.7644176527696676 0.8075834351649875\n",
      "\t 7 0.7577637743097725 0.8048614450351074\n",
      "\t 8 0.7517973632387948 0.8011516238002102\n",
      "\t 9 0.7481722491445405 0.8018522888359825\n",
      "\t 10 0.7462540553364917 0.8002203469251667\n",
      "\tFinal 0.7416221467559038 0.8002203469251667\n",
      "---------Fold: 1 loss: 0.8002203469251667 ----------\n",
      "\t 0 1.3594149619578566 0.8570011443443798\n",
      "\t 1 0.8311167722105816 0.844124931995787\n",
      "\t 2 0.8156040060493418 0.8324472975091385\n",
      "\t 3 0.8001751464411078 0.8209430922396026\n",
      "\t 4 0.7860993047711032 0.8143730275959218\n",
      "\t 5 0.7753967575894289 0.8089528185629846\n",
      "\t 6 0.7675515915967703 0.8071812494152841\n",
      "\t 7 0.7623359436903949 0.8006287342156108\n",
      "\t 8 0.7536472211152317 0.800766701470754\n",
      "\t 9 0.7505915810830033 0.7961765459307617\n",
      "\t 10 0.7454094032088593 0.7954945351972836\n",
      "\tFinal 0.7415056359198855 0.7954945351972836\n",
      "---------Fold: 2 loss: 0.7954945351972836 ----------\n",
      "\t 0 1.3593157936146107 0.8583192234143115\n",
      "\t 1 0.8330793471089382 0.8494300981505079\n",
      "\t 2 0.8228823788209811 0.8307655442008743\n",
      "\t 3 0.8002597092881928 0.8187455967037457\n",
      "\t 4 0.7845589079569248 0.8114942277204589\n",
      "\t 5 0.7728908477273408 0.8057795418680119\n",
      "\t 6 0.7644648418258083 0.8018090832968853\n",
      "\t 7 0.7582612242903689 0.7997271842660967\n",
      "\t 8 0.753564590311903 0.7987015694790466\n",
      "\t 9 0.7495069315271319 0.7962131082109123\n",
      "\t 10 0.7441955565633486 0.7927200822092286\n",
      "\tFinal 0.7401034176724482 0.7927200822092286\n",
      "---------Fold: 3 loss: 0.7927200822092286 ----------\n",
      "\t 0 1.3611335318214648 0.857331600200762\n",
      "\t 1 0.8326899464896584 0.8496000269425343\n",
      "\t 2 0.8232230692933409 0.8300046748180773\n",
      "\t 3 0.8005094662452189 0.820755316918616\n",
      "\t 4 0.78754821285669 0.8136039018089365\n",
      "\t 5 0.7783608520187817 0.8074258822503824\n",
      "\t 6 0.7678856713906369 0.8025962172295297\n",
      "\t 7 0.7608091065460797 0.79966245270402\n",
      "\t 8 0.7545284865276871 0.7983086410625729\n",
      "\t 9 0.7500115014529115 0.7958909413529033\n",
      "\t 10 0.74665390903312 0.7923246508895435\n",
      "\tFinal 0.741964301475349 0.7923246508895435\n",
      "---------Fold: 4 loss: 0.7923246508895435 ----------\n",
      "\t 0 1.355654393905192 0.8619751230320132\n",
      "\t 1 0.8310436904151958 0.8494526726563293\n",
      "\t 2 0.8159068113510037 0.8344917787826118\n",
      "\t 3 0.7963129027139128 0.8244067891089436\n",
      "\t 4 0.7840625532684382 0.8164827038941619\n",
      "\t 5 0.7737975355154498 0.8151201068364252\n",
      "\t 6 0.7672576933814936 0.8107981841524801\n",
      "\t 7 0.7606053097383587 0.8087921633232201\n",
      "\t 8 0.7556836766753066 0.802940826113057\n",
      "\t 9 0.7480619783093579 0.8019854572321699\n",
      "\t 10 0.7456555199374262 0.7993760760600198\n",
      "\tFinal 0.7418148156350273 0.7993760760600198\n",
      "---------Fold: 5 loss: 0.7993760760600198 ----------\n",
      "Best F is: 9 corresponding loss is: 0.7960271382562484\n",
      "F 10\n",
      "\t 0 1.3477489710125492 0.8609719588157692\n",
      "\t 1 0.8296905121216814 0.8543283820344183\n",
      "\t 2 0.8190914519783545 0.8341992880142396\n",
      "\t 3 0.7983692505286833 0.8249100734723848\n",
      "\t 4 0.7844316955361228 0.8173317991039103\n",
      "\t 5 0.7732618759713504 0.8101948099112163\n",
      "\t 6 0.7646900150257854 0.8070054955428957\n",
      "\t 7 0.7576215611420631 0.805611223928015\n",
      "\t 8 0.7527776159177215 0.801868188461104\n",
      "\t 9 0.747065090308656 0.7983061229339924\n",
      "\t 10 0.7439819004066178 0.7984673786473233\n",
      "\tFinal 0.7429063436564829 0.7984673786473233\n",
      "---------Fold: 1 loss: 0.7984673786473233 ----------\n",
      "\t 0 1.347244439245794 0.8596238255463693\n",
      "\t 1 0.8313734636257786 0.8432156219336508\n",
      "\t 2 0.8141771657670593 0.8282077902290818\n",
      "\t 3 0.7956125339328505 0.819950657474971\n",
      "\t 4 0.7855257509437339 0.8122685662936353\n",
      "\t 5 0.7728419712511012 0.8054298650946359\n",
      "\t 6 0.7630017347756033 0.8022325881123131\n",
      "\t 7 0.7552739472727447 0.797880885652685\n",
      "\t 8 0.7496054858441251 0.7973950936638979\n",
      "\t 9 0.745359112018559 0.7939620733212654\n",
      "\t 10 0.7409483870235419 0.7897170883943048\n",
      "\tFinal 0.7358599772004776 0.7897170883943048\n",
      "---------Fold: 2 loss: 0.7897170883943048 ----------\n",
      "\t 0 1.3475765837340665 0.8546835284561287\n",
      "\t 1 0.829774264819324 0.8453160564025627\n",
      "\t 2 0.8185239185729631 0.8296304699716563\n",
      "\t 3 0.7978969014243185 0.8189057064756082\n",
      "\t 4 0.7837332909723758 0.8117722472288024\n",
      "\t 5 0.7742822654568019 0.8074030721815435\n",
      "\t 6 0.7649853196710014 0.8024120407126475\n",
      "\t 7 0.7572536396488364 0.7971368445036281\n",
      "\t 8 0.7503442646329727 0.7978301540340438\n",
      "\t 9 0.7479342378165291 0.7945857369601826\n",
      "\t 10 0.7418588159089002 0.7919156671405359\n",
      "\tFinal 0.738610509942025 0.7919156671405359\n",
      "---------Fold: 3 loss: 0.7919156671405359 ----------\n",
      "\t 0 1.3487660874044705 0.8554722882741039\n",
      "\t 1 0.8304529814395192 0.8443282701254206\n",
      "\t 2 0.8166552732634194 0.8264862756050059\n",
      "\t 3 0.7962933506385672 0.8198055709657757\n",
      "\t 4 0.786311499414362 0.8112535153636921\n",
      "\t 5 0.7744558271313366 0.8062075539659163\n",
      "\t 6 0.7645154491448912 0.8036520068205976\n",
      "\t 7 0.7590314026003623 0.798998931826433\n",
      "\t 8 0.7536024280900364 0.7975762739076819\n",
      "\t 9 0.7475224047184754 0.7913434681929831\n",
      "\t 10 0.7422920072748237 0.7926538364237423\n",
      "\tFinal 0.7396399785746082 0.7926538364237423\n",
      "---------Fold: 4 loss: 0.7926538364237423 ----------\n",
      "\t 0 1.3473719697648658 0.8624630163534737\n",
      "\t 1 0.8306748175045328 0.8531211431638256\n",
      "\t 2 0.8191298805718459 0.8357084848272628\n",
      "\t 3 0.7959801244216539 0.8261974994009953\n",
      "\t 4 0.7857839725350478 0.8167542781435096\n",
      "\t 5 0.7717287188751945 0.8096427467500342\n",
      "\t 6 0.76176053160694 0.806873029786246\n",
      "\t 7 0.7560153518369599 0.8050731428811744\n",
      "\t 8 0.7506579240852471 0.8018793135070681\n",
      "\t 9 0.7457451244585678 0.8015606515624975\n",
      "\t 10 0.7431108172054772 0.7998252588021497\n",
      "\tFinal 0.7403025036335723 0.7998252588021497\n",
      "---------Fold: 5 loss: 0.7998252588021497 ----------\n",
      "Best F is: 10 corresponding loss is: 0.7945158458816112\n",
      "F 11\n",
      "\t 0 1.3353180431779565 0.8618135831710786\n",
      "\t 1 0.8283810781443549 0.8488541665225786\n",
      "\t 2 0.8134611329902487 0.8326796849027509\n",
      "\t 3 0.7950877938784868 0.8232488101828708\n",
      "\t 4 0.78222197195291 0.8166003930468572\n",
      "\t 5 0.7722977709623459 0.8118248409526718\n",
      "\t 6 0.7640537379340763 0.8061716513861172\n",
      "\t 7 0.7559557898093634 0.8043925993063116\n",
      "\t 8 0.7510447367838919 0.8008677936460243\n",
      "\t 9 0.7437609567051982 0.7998849526037749\n",
      "\t 10 0.7401377693182731 0.7952252538988606\n",
      "\tFinal 0.7370899697956557 0.7952252538988606\n",
      "---------Fold: 1 loss: 0.7952252538988606 ----------\n",
      "\t 0 1.340461380277597 0.8584205099854236\n",
      "\t 1 0.8311817744256238 0.8450058119732278\n",
      "\t 2 0.8156306563634055 0.8296374910747691\n",
      "\t 3 0.7959091319682324 0.8208985779746686\n",
      "\t 4 0.7830314824751184 0.8109504531959985\n",
      "\t 5 0.7723601238963366 0.8063845789036088\n",
      "\t 6 0.7622930291572093 0.7980684013337978\n",
      "\t 7 0.7534435985607212 0.7981908205284024\n",
      "\t 8 0.748875256966213 0.7957511074281857\n",
      "\t 9 0.7455419862229823 0.7950975653661478\n",
      "\t 10 0.7414737217181608 0.7928927781183761\n",
      "\tFinal 0.7376597703001689 0.7928927781183761\n",
      "---------Fold: 2 loss: 0.7928927781183761 ----------\n",
      "\t 0 1.338271474397914 0.8566569681853593\n",
      "\t 1 0.8310974079576539 0.844401662553688\n",
      "\t 2 0.8164938575937973 0.8284969174197667\n",
      "\t 3 0.7965763565593735 0.8183065627078692\n",
      "\t 4 0.7818460685028226 0.8098059525347259\n",
      "\t 5 0.7714089320255294 0.8052718205902641\n",
      "\t 6 0.762063552000088 0.8003433939268086\n",
      "\t 7 0.7561890710472837 0.7956656939237271\n",
      "\t 8 0.7471513102832766 0.7942042835742151\n",
      "\t 9 0.7446702553818688 0.7923278658447781\n",
      "\t 10 0.7406952743762879 0.793599164983367\n",
      "\tFinal 0.7370611104810637 0.793599164983367\n",
      "---------Fold: 3 loss: 0.793599164983367 ----------\n",
      "\t 0 1.3386474315553245 0.8594546913134826\n",
      "\t 1 0.8315241138877953 0.8448185488658976\n",
      "\t 2 0.8170661306972149 0.8266499237247639\n",
      "\t 3 0.7959969514767515 0.8187224962104691\n",
      "\t 4 0.7841928612179337 0.8078588164867073\n",
      "\t 5 0.7716232898387825 0.8066145982277384\n",
      "\t 6 0.7639952879866035 0.8008475488476815\n",
      "\t 7 0.7563946627316881 0.7989371711390607\n",
      "\t 8 0.7512516879512875 0.7952909216474261\n",
      "\t 9 0.7479519389990101 0.7923354763297968\n",
      "\t 10 0.7401990572373187 0.7922524677048794\n",
      "\tFinal 0.7377875593359762 0.7922524677048794\n",
      "---------Fold: 4 loss: 0.7922524677048794 ----------\n",
      "\t 0 1.3383037346295295 0.8605182108902151\n",
      "\t 1 0.8287737847704085 0.8498456711798932\n",
      "\t 2 0.8157660062067551 0.8343042088152774\n",
      "\t 3 0.7956155358800316 0.8251715572522391\n",
      "\t 4 0.7831161437529672 0.8200276440939801\n",
      "\t 5 0.7749447670213911 0.8131658447601595\n",
      "\t 6 0.7658094785721421 0.8099862126294187\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t 7 0.7587982253608634 0.8045505978602636\n",
      "\t 8 0.7509611112633298 0.8041997347644375\n",
      "\t 9 0.7476583243608562 0.8031043124903006\n",
      "\t 10 0.742675440850691 0.7980478179878127\n",
      "\tFinal 0.7371756949855092 0.7980478179878127\n",
      "---------Fold: 5 loss: 0.7980478179878127 ----------\n",
      "Best F is: 11 corresponding loss is: 0.7944034965386592\n"
     ]
    }
   ],
   "source": [
    "Fs = [9,10,11]\n",
    "final1 = []\n",
    "best_loss = 10\n",
    "best_F = 0\n",
    "for F in Fs:\n",
    "    print('F',F)\n",
    "    model = RecommenderModel(F=F,lr=0.05,step=11,B=60,p=0.1)\n",
    "    loss2 = cross_validation(model,users,movies,ratings,folds)\n",
    "    final1.append((F,loss2))\n",
    "    if loss1 < best_loss:\n",
    "        best_loss = loss2\n",
    "        best_F = F\n",
    "    print('Best F is:', F,'corresponding loss is:',loss2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F</th>\n",
       "      <th>loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>0.796027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>0.794516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>0.794403</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    F      loss\n",
       "0   9  0.796027\n",
       "1  10  0.794516\n",
       "2  11  0.794403"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final1_df = pd.DataFrame(final1,columns = ['F','loss'])\n",
    "final1_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting F = 11 and Batch size = 60 as the optimal tuning parameter, and fit the model to the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t 0 1.3390383116635098 0.8311222169311986\n",
      "\t 1 0.8325067236173415 0.8106261859832328\n",
      "\t 2 0.809836904018346 0.7967817029119547\n",
      "\t 3 0.7984389232916002 0.783844860568531\n",
      "\t 4 0.7841417983389678 0.7742220535102295\n",
      "\t 5 0.7746864396308372 0.7668519277118556\n",
      "\t 6 0.7674505172452754 0.7614489527790336\n",
      "\t 7 0.7618282938077128 0.7559221944532081\n",
      "\t 8 0.7575015438119574 0.7522868279067578\n",
      "\t 9 0.7537663712957845 0.7492715266409525\n",
      "\t 10 0.7499332060560542 0.7476959671438216\n",
      "\tFinal 0.7482201142031257 0.7476959671438216\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7476959671438216"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RecommenderModel(F=11,lr=0.05,step=11,B=60,p=0.1)\n",
    "model.fit(users,movies,ratings,user_test,movie_test,rating_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The final loss is 0.7476 after fitting the Recommender Model with parameters (F = 11, learning rate = 0.05, step = 11, Batchc size = 60, penalty = 0.1) on the entire dataset, and test on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
