{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus Homework 7: CIFAR10 Image Classification problem\n",
    "\n",
    "We train two small convolutional neural networks on the CIFAR10 dataset. \n",
    "\n",
    "Data can be downloaded from the [University of Toronto](https://www.cs.toronto.edu/~kriz/cifar.html) Web Site.\n",
    "This homework assumes you have extracted the contents of the file `https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz` some where accessible in your hard drive.\n",
    "\n",
    "\n",
    "This optional homework requires you to train a Convolutional Neural Networ using the CIFAR10 dataset. Training will be **much faster** if you run this notebook on a machine with `GPU`. Follow the instructions provided with this notebook to provision a machine on `gcloud` and configure it to be be able to run this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-18T11:11:08.082731Z",
     "start_time": "2019-04-18T11:11:04.513257Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "print(tf.__version__)\n",
    "\n",
    "import pickle\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../..\")\n",
    "from E4525_ML.notebook_utils import get_logger,LoggingCallback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set up a logger so that we can save to a file intermediate calculation results as they occur in the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-18T11:11:08.088720Z",
     "start_time": "2019-04-18T11:11:08.084710Z"
    }
   },
   "outputs": [],
   "source": [
    "logger=get_logger(\"Bonus_Homework_CIFAR10.log\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following lines avoid crashes on certain `NVDIA` `GPU`s for some versions of `tensorflow`. It may not be needed on the `gcloud` machines as configured."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-18T11:11:08.910445Z",
     "start_time": "2019-04-18T11:11:08.090689Z"
    }
   },
   "outputs": [],
   "source": [
    "#\n",
    "from tensorflow.keras.backend import set_session\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True  # dynamically grow the memory used on the GPU\n",
    "#config.log_device_placement = True  # to log device placement (on which device the operation ran)\n",
    "                                    # (nothing gets printed in Jupyter, only if you run it standalone)\n",
    "\n",
    "sess = tf.Session(config=config)\n",
    "\n",
    "set_session(sess)  # set this TensorFlow session as the default session for Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "`CIFAR10` s separated into batches, we read them all and aggregate them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"> Problem 0.0 </div>\n",
    "Download the CIFAR-10 image data set from `https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz` extract its contents into the `raw_data_dir` directory defined below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-18T11:11:08.916426Z",
     "start_time": "2019-04-18T11:11:08.912446Z"
    }
   },
   "outputs": [],
   "source": [
    "raw_data_dir=\"../../raw/CIFAR-10-Images/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"> Problem 0.1 </div>\n",
    "Process the main and test  datasets  using the formulas below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-18T11:11:08.934378Z",
     "start_time": "2019-04-18T11:11:08.918429Z"
    }
   },
   "outputs": [],
   "source": [
    "def unpickle(filename):\n",
    "    import pickle\n",
    "    with open(filename, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we re-scale colors to the range $[0,1]$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-18T11:11:08.944351Z",
     "start_time": "2019-04-18T11:11:08.936372Z"
    }
   },
   "outputs": [],
   "source": [
    "def process(filename):\n",
    "    dic=unpickle(filename)\n",
    "    labels=dic[b\"labels\"]\n",
    "    data=dic[b\"data\"]\n",
    "    images=data.reshape(10000, 3, 32, 32).transpose(0,2,3,1).astype(\"uint8\")\n",
    "    return images/255.0,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-18T11:11:10.355575Z",
     "start_time": "2019-04-18T11:11:08.946346Z"
    }
   },
   "outputs": [],
   "source": [
    "images=[]\n",
    "labels=[]\n",
    "for idx in range(1,6):\n",
    "    filename=raw_data_dir+f\"data_batch_{idx}\"\n",
    "    img,lab=process(filename)\n",
    "    images.append(img)\n",
    "    labels.append(lab)\n",
    "\n",
    "images=np.concatenate(images)\n",
    "labels=np.concatenate(labels)\n",
    "\n",
    "images.shape,labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-18T11:11:10.524156Z",
     "start_time": "2019-04-18T11:11:10.357571Z"
    }
   },
   "outputs": [],
   "source": [
    "filename=raw_data_dir+f\"test_batch\"\n",
    "images_test,labels_test=process(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-18T11:11:10.531105Z",
     "start_time": "2019-04-18T11:11:10.525122Z"
    }
   },
   "outputs": [],
   "source": [
    "filename=raw_data_dir+f\"batches.meta\"\n",
    "meta_data=unpickle(filename)\n",
    "label_names=meta_data[b\"label_names\"]\n",
    "label_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The images are truly tiny and have very low resolution!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-18T11:11:11.080885Z",
     "start_time": "2019-04-18T11:11:10.532106Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "for i in range(8):\n",
    "    plt.subplot(2, 4, i+1)\n",
    "    plt.imshow(images[i])\n",
    "    label=label_names[labels[i]].decode(\"ascii\")\n",
    "    plt.title(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"> Problem 0.2 </div>\n",
    "Separate the main dataset into a training set and a valuation set with 20% of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-18T11:11:12.810262Z",
     "start_time": "2019-04-18T11:11:11.082848Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple  Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-18T09:51:58.701568Z",
     "start_time": "2019-04-18T09:51:58.672666Z"
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-info\"> Problem 1.0 </div>\n",
    "Using the `keras` library build a convolutional network containing the following layers\n",
    "1. A Convolutional layer with a $5\\times 5$ kernel, 32 output channels and `relu` activation\n",
    "2. A Max pooling layer with a $2\\times 2$ stride.\n",
    "3. A 30% dropout layer\n",
    "4. A Convolutional layer with a $5\\times 5$ kernel, 64 output channels and `relu` activation\n",
    "5. A Max pooling layer with a $2\\times 2$ stride.\n",
    "6. A 30% dropout layer\n",
    "7. A Dense layer with 128 hidden units and `relu` activation\n",
    "8. A 25% dropout layer\n",
    "9. A Dense layer with 64 hidden units and `relu` activation\n",
    "10. A 25% dropout layer\n",
    "11. A final softmax layer that output the probabilities of the sample belonging to each one of the image classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-18T11:11:13.007750Z",
     "start_time": "2019-04-18T11:11:12.812222Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"> Problem 1.1 </div>\n",
    "Compile the model. Set it up so that it uses the `Adam` optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-18T11:11:13.090535Z",
     "start_time": "2019-04-18T11:11:13.008697Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"> Problem 1.2 </div>\n",
    "How many learnable parameters are in each layer, an in total?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-18T11:11:13.097469Z",
     "start_time": "2019-04-18T11:11:13.091474Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"> Problem 1.3 </div>\n",
    "Train the model over 100 epochs, and a batch size of 128. \n",
    "\n",
    "Use the validation sets you created before for validation as you optimize.\n",
    "\n",
    "Make sure to collect the results returned by the `fit` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-18T11:11:13.111445Z",
     "start_time": "2019-04-18T11:11:13.098457Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"> Problem 1.4 </div>\n",
    "Plot the training history of loss and accuracy as a function of traning epoch for both training and validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-18T11:19:02.853770Z",
     "start_time": "2019-04-18T11:19:02.543654Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"> Problem 1.4 </div>\n",
    "What accuracy did you achieve on the validation set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-18T11:19:03.619723Z",
     "start_time": "2019-04-18T11:19:02.855768Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Larger Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"> Problem 2.0 </div>\n",
    "Using the `keras` library build a convolutional network containing the following layers\n",
    "1. A Convolutional layer with a $3\\times 3$ kernel, 32 output channels and `relu` activation\n",
    "3. A 25% dropout layer\n",
    "1. A Convolutional layer with a $3\\times 3$ kernel, 32 output channels and `relu` activation\n",
    "2. A Max pooling layer with a $2\\times 2$ stride.\n",
    "3. A 25% dropout layer\n",
    "1. A Convolutional layer with a $3\\times 3$ kernel, 32 output channels and `relu` activation\n",
    "3. A 25% dropout layer\n",
    "4. A Convolutional layer with a $3\\times 3$ kernel, 64 output channels and `relu` activation\n",
    "2. A Max pooling layer with a $2\\times 2$ stride.\n",
    "3. A 50% dropout layer\n",
    "4. A Convolutional layer with a $3\\times 3$ kernel, 64 output channels and `relu` activation\n",
    "3. A 25% dropout layer\n",
    "5. A Convolutional layer with a $3\\times 3$ kernel, 1024 output channels and `relu` activation\n",
    "6. An Average pooling layer wit $8\\times 8$ stride.\n",
    "3. A 25% dropout layer\n",
    "7. A Dense layer with 512 hidden units and `relu` activation\n",
    "8. A 40% dropout layer\n",
    "9. A Dense layer with 256 hidden units and `relu` activation\n",
    "10. A 40% dropout layer\n",
    "11. A final softmax layer that output the probabilities of the sample belonging to each one of the image classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-18T11:19:03.934922Z",
     "start_time": "2019-04-18T11:19:03.621720Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"> Problem 2.1 </div>\n",
    "Compile the model. Set it up so that it uses the `Adam` optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-18T11:19:04.016752Z",
     "start_time": "2019-04-18T11:19:03.936874Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-18T10:24:10.568430Z",
     "start_time": "2019-04-18T10:24:10.563321Z"
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-info\"> Problem 2.2 </div>\n",
    "How many parameters are in total? What layers contribute the most learnable parameters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-18T11:19:04.025639Z",
     "start_time": "2019-04-18T11:19:04.019654Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"> Problem 2.3 </div>\n",
    "Train the model over 100 epochs, and a batch size of 128. \n",
    "\n",
    "Use the validation sets you created before for validation as you optimize.\n",
    "\n",
    "Make sure to collect the results returned by the `fit` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-18T11:36:12.050575Z",
     "start_time": "2019-04-18T11:19:04.027632Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-18T10:25:45.966990Z",
     "start_time": "2019-04-18T10:25:45.958300Z"
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-info\"> Problem 2.4 </div>\n",
    "Plot the training history of loss and accuracy as a function of traning epoch for both training and validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-18T11:36:12.309953Z",
     "start_time": "2019-04-18T11:36:12.052621Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-18T10:28:41.585775Z",
     "start_time": "2019-04-18T10:28:41.581583Z"
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-info\"> Problem 2.4 </div>\n",
    "What accuracy did you achieve on the validation set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-18T11:36:13.580550Z",
     "start_time": "2019-04-18T11:36:12.311913Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test of Best Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"> Problem 3.0 </div>\n",
    "Of the two models that you have trained, select the one that had better performance on the valuation set.\n",
    "Refit the model (100 epochs) to all the training + validation data and test is performance with the test dataset.\n",
    "\n",
    "[**Note**: for faster convergence you can re-start fitting the model you already learned on the training set]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-18T11:58:02.994920Z",
     "start_time": "2019-04-18T11:36:13.581544Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-18T10:36:56.450771Z",
     "start_time": "2019-04-18T10:36:56.446054Z"
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-info\"> Problem 3.1 </div>\n",
    "What accuracy did you achieve on the test set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-18T11:58:04.161836Z",
     "start_time": "2019-04-18T11:58:02.997917Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
